{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## module 1,2,3 combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will record continuos audio and transcribe them it the set of 10 second audio clips until an stop event occure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5 (record_audio):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Lenovo\\Documents\\Rohit_AI_ML\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_16340\\419449550.py\", line 153, in record_audio\n",
      "  File \"c:\\Users\\Lenovo\\Documents\\Rohit_AI_ML\\.venv\\lib\\site-packages\\pyaudio\\__init__.py\", line 639, in open\n",
      "    stream = PyAudio.Stream(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\Lenovo\\Documents\\Rohit_AI_ML\\.venv\\lib\\site-packages\\pyaudio\\__init__.py\", line 441, in __init__\n",
      "    self._stream = pa.open(**arguments)\n",
      "OSError: [Errno -9996] Invalid input device (no default output device)\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import pyaudio\n",
    "import wave\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from transformers import BertTokenizer, BertModel, BartForConditionalGeneration, BartTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import threading\n",
    "\n",
    "# Parameters\n",
    "FORMAT = pyaudio.paInt16  # Audio format\n",
    "CHANNELS = 1  # Number of channels\n",
    "RATE = 44100  # Sample rate (Hz)\n",
    "CHUNK = 1024  # Chunk size (number of frames per buffer)\n",
    "RECORD_SECONDS = 10  # Duration of each recording (seconds)\n",
    "OUTPUT_FILENAME = \"recorded_audio.wav\"  # Output filename\n",
    "\n",
    "# Initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained BART model and tokenizer for summarization\n",
    "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "# Loading the dataset of keywords\n",
    "datapath = r\"C:\\Users\\Lenovo\\Documents\\Rohit_AI_ML\\SummariseIT\\dataset.csv\"\n",
    "df = pd.read_csv(datapath)\n",
    "# Flatten the dataset to create a set of valid keywords\n",
    "valid_keywords = set()\n",
    "for column in df.columns:\n",
    "    valid_keywords.update(df[column].dropna().str.strip().tolist())\n",
    "\n",
    "def extract_keywords_from_tokens(text, model, tokenizer, num_keywords=5):\n",
    "    \"\"\"Extract keywords from the text using BERT embeddings.\"\"\"\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "    # Convert token IDs to tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    \n",
    "    # Get the [CLS] token's embedding\n",
    "    cls_embedding = last_hidden_state[:, 0, :].squeeze()\n",
    "    \n",
    "    # Calculate similarity between each token embedding and the [CLS] embedding\n",
    "    similarities = torch.matmul(last_hidden_state.squeeze(), cls_embedding)\n",
    "    \n",
    "    # Get the indices of the top-n tokens with the highest similarity\n",
    "    top_indices = similarities.topk(num_keywords).indices\n",
    "\n",
    "    # Extract the corresponding tokens, excluding [CLS] and checking if they are in valid_keywords\n",
    "    keywords = [tokens[i] for i in top_indices if tokens[i] != '[CLS]' and tokens[i] in valid_keywords]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def generate_summary(text, model, tokenizer):\n",
    "    \"\"\"Generate a summary using BART model.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=1024)\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=150, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "def process_transcription(text):\n",
    "    \"\"\"Process the transcribed text: extract keywords and generate summaries.\"\"\"\n",
    "    # Save the transcription to a text file\n",
    "    with open(\"transcription.txt\", \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation and make lowercase\n",
    "    words = [word.lower() for word in words if word.isalnum()]\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Count the frequency of each word\n",
    "    word_freq = Counter(filtered_words)\n",
    "\n",
    "    # Select the top N keywords (you can adjust N as needed)\n",
    "    N = 10\n",
    "    keywords = word_freq.most_common(N)\n",
    "\n",
    "    # Print the keywords\n",
    "    print(\"Top keywords:\")\n",
    "    for keyword, freq in keywords:\n",
    "        print(f\"{keyword}: {freq}\")\n",
    "\n",
    "    # Save the keywords to a text file\n",
    "    with open(\"keywords.txt\", \"w\") as f:\n",
    "        for keyword, freq in keywords:\n",
    "            f.write(f\"{keyword}\\n\")\n",
    "    \n",
    "    # Extract and summarize keywords\n",
    "    extracted_keywords = extract_keywords_from_tokens(text, bert_model, bert_tokenizer)\n",
    "    \n",
    "    # Print extracted keywords and their summaries\n",
    "    print(\"Extracted keywords:\")\n",
    "    for idx, keyword in enumerate(extracted_keywords, start=1):\n",
    "        print(f\"Keyword {idx}: {keyword}\")\n",
    "\n",
    "        # Search the web for the keyword on Wikipedia\n",
    "        search_url = f\"https://en.wikipedia.org/wiki/{keyword}\"\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n",
    "        response = requests.get(search_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Extract the relevant information from the search result\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        extracted_text = \"\"\n",
    "        for paragraph in paragraphs:\n",
    "            extracted_text += paragraph.get_text() + \" \"\n",
    "        extracted_text = extracted_text.strip()\n",
    "\n",
    "        # Generate summary\n",
    "        summary = generate_summary(extracted_text, bart_model, bart_tokenizer)\n",
    "        print(f\"Summary of {keyword}:\")\n",
    "        print(summary)\n",
    "\n",
    "def continuous_recording():\n",
    "    \"\"\"Record audio in 10-second intervals and process the transcription in real-time.\"\"\"\n",
    "    try:\n",
    "        # Initialize PyAudio\n",
    "        audio = pyaudio.PyAudio()\n",
    "\n",
    "        # Check for input devices\n",
    "        if audio.get_device_count() == 0:\n",
    "            print(\"No input device found. Exiting.\")\n",
    "            return\n",
    "\n",
    "        streams = []\n",
    "\n",
    "        def record_audio():\n",
    "            \"\"\"Record audio continuously in 10-second intervals.\"\"\"\n",
    "            while not stop_event.is_set():\n",
    "                stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                                    rate=RATE, input=True,\n",
    "                                    frames_per_buffer=CHUNK)\n",
    "                streams.append(stream)\n",
    "                frames = []\n",
    "\n",
    "                for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "                    data = stream.read(CHUNK)\n",
    "                    frames.append(data)\n",
    "\n",
    "                # Save the recorded data as a WAV file\n",
    "                with wave.open(OUTPUT_FILENAME, 'wb') as wf:\n",
    "                    wf.setnchannels(CHANNELS)\n",
    "                    wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "                    wf.setframerate(RATE)\n",
    "                    wf.writeframes(b''.join(frames))\n",
    "\n",
    "                stream.stop_stream()\n",
    "                streams.remove(stream)\n",
    "                stream.close()\n",
    "\n",
    "        def transcribe_audio():\n",
    "            \"\"\"Transcribe the recorded audio in real-time.\"\"\"\n",
    "            while not stop_event.is_set():\n",
    "                if streams:\n",
    "                    with sr.AudioFile(OUTPUT_FILENAME) as source:\n",
    "                        audio_data = r.record(source)\n",
    "                        try:\n",
    "                            # Recognize the speech using Google Web Speech API\n",
    "                            text = r.recognize_google(audio_data)\n",
    "                            print(\"Transcription: \" + text)\n",
    "                            process_transcription(text)\n",
    "                        except sr.UnknownValueError:\n",
    "                            print(\"Google Speech Recognition could not understand the audio\")\n",
    "                        except sr.RequestError as e:\n",
    "                            print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "        # Create and start the recording and transcribing threads\n",
    "        record_thread = threading.Thread(target=record_audio)\n",
    "        transcribe_thread = threading.Thread(target=transcribe_audio)\n",
    "        record_thread.start()\n",
    "        transcribe_thread.start()\n",
    "\n",
    "        # Wait for interrupt signal to stop recording\n",
    "        input(\"Press Enter to stop recording...\\n\")\n",
    "        stop_event.set()\n",
    "\n",
    "        # Ensure threads complete their work\n",
    "        record_thread.join()\n",
    "        transcribe_thread.join()\n",
    "\n",
    "        # Terminate PyAudio instance\n",
    "        audio.terminate()\n",
    "\n",
    "    except OSError as e:\n",
    "        print(f\"OSError encountered: {e}\")\n",
    "\n",
    "# Initialize an event to handle stop signal\n",
    "stop_event = threading.Event()\n",
    "\n",
    "# Start continuous recording and transcription\n",
    "continuous_recording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
